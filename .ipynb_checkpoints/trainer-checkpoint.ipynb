{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92cdc9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68aded50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "# when transfer, color value is divided by 255\n",
    "loader = transforms.Compose([transforms.ToTensor()])  \n",
    "unloader = transforms.ToPILImage()\n",
    "preprocess = transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddef8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    def __init__(self, mask_dir, img_dir, img_transform = None):\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.n_mask = len(os.listdir(self.mask_dir))\n",
    "        self.n_img = len(os.listdir(self.img_dir))\n",
    "        self.img_transform = img_transform\n",
    "\n",
    "    def __len__(self):     \n",
    "        return min(self.n_img, self.n_mask)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        filename = os.listdir(self.img_dir)[idx]\n",
    "        \n",
    "        img_path = f\"{self.img_dir}{filename}\"\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.img_transform:\n",
    "            img = self.img_transform(img)        \n",
    "        \n",
    "        mask_path = f\"{self.mask_dir}{filename}\"\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "#         plt.imshow(mask, cmap=\"gray\")\n",
    "        mask = np.asarray(mask)\n",
    "        mask[mask>200]=255    # black:0, white: 255\n",
    "        mask[mask<=200]=0\n",
    "        mask = mask/255\n",
    "#         plt.imshow(mask, cmap=\"gray\")\n",
    "        mask=mask[np.newaxis,:, :]\n",
    "        mask = torch.Tensor(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "train_mask_dir = f\"./images/train/mask/\"\n",
    "train_img_dir = f\"./images/train/img/\"\n",
    "training_set = SegDataset(train_mask_dir,train_img_dir, preprocess)\n",
    "training_generator = DataLoader(training_set, batch_size=2, shuffle=True)\n",
    "\n",
    "val_mask_dir = f\"./images/validation/mask/\"\n",
    "val_img_dir = f\"./images/validation/img/\"\n",
    "validation_set = SegDataset(val_mask_dir, val_img_dir, preprocess)\n",
    "validation_generator = DataLoader(validation_set, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b3c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDeepLabv3(outputchannels=1):\n",
    "    \"\"\"DeepLabv3 class with custom head\n",
    "    Args:\n",
    "        outputchannels (int, optional): The number of output channels\n",
    "        in your dataset masks. Defaults to 1.\n",
    "    Returns:\n",
    "        model: Returns the DeepLabv3 model with the ResNet101 backbone.\n",
    "    \"\"\"\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=True,\n",
    "                                                    progress=True)\n",
    "    model.classifier = DeepLabHead(2048, outputchannels)\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    return model\n",
    "\n",
    "model = createDeepLabv3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee392f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "num_epochs = 10\n",
    "\n",
    "# Specify the loss function\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "# Specify the optimizer with a lower learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for (img, mask) in iter(training_generator):\n",
    "        img = img.to(device).to(torch.float32)\n",
    "        mask = mask.to(device).to(torch.float32)\n",
    "        output = model(img)['out']\n",
    "        loss = criterion(output, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "    print(f\"Epoch {epoch}: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./ignore/trained_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
