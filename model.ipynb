{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a6b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantcv import plantcv as pcv\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# n = 1\n",
    "# img_path = f\"./images/sized/{n}.jpg\"\n",
    "# img, _, _ = pcv.readimage(filename=img_path, mode='rgb')\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c8d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt, _, _ = pcv.readimage(filename=\"./tt.png\", mode=\"rgb\")\n",
    "# tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a8f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_path = f\"./images/mask/{n}.jpg\"\n",
    "# mask, _, _ = pcv.readimage(filename=mask_path, mode=\"gray\")\n",
    "# # black:0, white: 255\n",
    "# mask[mask>0]=1\n",
    "# mask=mask[:, :, np.newaxis]\n",
    "# mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdfb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class SegDataset(Dataset):\n",
    "    def __init__(self, mask_dir, img_dir, transform=None, mask_transform=None):\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.n_mask = len(os.listdir(self.mask_dir))\n",
    "        self.n_img = len(os.listdir(self.img_dir))\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):     \n",
    "        return min(self.n_img, self.n_mask)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        filename = os.listdir(self.img_dir)[idx]\n",
    "        \n",
    "        img_path = f\"{self.img_dir}{filename}\"\n",
    "        img, _, _ = pcv.readimage(filename=img_path, mode='rgb')\n",
    "        img = img/255\n",
    "        \"\"\"\n",
    "        Normalization to be added\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \"\"\"\n",
    "        # plantcv read returns image by Height x Width x Channels\n",
    "        img = np.transpose(img, (2,0,1))\n",
    "        # adjust image dimension to Channels x Height x Width\n",
    "        \n",
    "        mask_path = f\"{self.mask_dir}{filename}\"\n",
    "        mask, _, _ = pcv.readimage(filename=mask_path, mode=\"gray\")\n",
    "        mask[mask>0]=1    # black:0, white: 255\n",
    "        mask=mask[np.newaxis,:, :]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(img)\n",
    "        if self.mask_transform:\n",
    "            label = self.mask_transform(mask)\n",
    "        return img, mask\n",
    "\n",
    "train_mask_dir = f\"./images/train/mask/\"\n",
    "train_img_dir = f\"./images/train/img/\"\n",
    "training_set = SegDataset(train_mask_dir, train_img_dir)\n",
    "training_generator = DataLoader(training_set, batch_size=2, shuffle=True)\n",
    "\n",
    "val_mask_dir = f\"./images/validation/mask/\"\n",
    "val_img_dir = f\"./images/validation/img/\"\n",
    "validation_set = SegDataset(val_mask_dir, val_img_dir)\n",
    "validation_generator = DataLoader(validation_set, batch_size=2, shuffle=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998d05b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'list'> 2\n",
      "\n",
      " <class 'torch.Tensor'> torch.Size([2, 3, 500, 500])\n",
      "tensor([[[[0.1765, 0.1608, 0.1569,  ..., 0.3333, 0.3647, 0.3529],\n",
      "          [0.1412, 0.1294, 0.1255,  ..., 0.3490, 0.3647, 0.4000],\n",
      "          [0.1451, 0.1373, 0.1216,  ..., 0.3725, 0.3647, 0.4235],\n",
      "          ...,\n",
      "          [0.2196, 0.1882, 0.2784,  ..., 0.2078, 0.2314, 0.2275],\n",
      "          [0.1765, 0.1843, 0.2588,  ..., 0.1882, 0.2039, 0.2000],\n",
      "          [0.2314, 0.1294, 0.1412,  ..., 0.1725, 0.1804, 0.1765]],\n",
      "\n",
      "         [[0.1373, 0.1216, 0.1137,  ..., 0.4745, 0.5059, 0.4941],\n",
      "          [0.0941, 0.0902, 0.0863,  ..., 0.4902, 0.5059, 0.5412],\n",
      "          [0.1020, 0.0941, 0.0824,  ..., 0.5137, 0.5059, 0.5647],\n",
      "          ...,\n",
      "          [0.2039, 0.1725, 0.2431,  ..., 0.1255, 0.1490, 0.1373],\n",
      "          [0.1608, 0.1686, 0.2235,  ..., 0.1059, 0.1216, 0.1098],\n",
      "          [0.2118, 0.1098, 0.1020,  ..., 0.0902, 0.0980, 0.0863]],\n",
      "\n",
      "         [[0.0706, 0.0549, 0.0588,  ..., 0.1451, 0.1765, 0.1725],\n",
      "          [0.0235, 0.0235, 0.0196,  ..., 0.1608, 0.1765, 0.2196],\n",
      "          [0.0235, 0.0157, 0.0118,  ..., 0.1843, 0.1765, 0.2431],\n",
      "          ...,\n",
      "          [0.0941, 0.0627, 0.1373,  ..., 0.0392, 0.0627, 0.0510],\n",
      "          [0.0510, 0.0588, 0.1176,  ..., 0.0196, 0.0353, 0.0235],\n",
      "          [0.1137, 0.0118, 0.0078,  ..., 0.0039, 0.0118, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0980, 0.0941, 0.0902,  ..., 0.2549, 0.2549, 0.2549],\n",
      "          [0.0902, 0.0863, 0.0824,  ..., 0.2471, 0.2471, 0.2471],\n",
      "          [0.0784, 0.0745, 0.0706,  ..., 0.2471, 0.2471, 0.2471],\n",
      "          ...,\n",
      "          [0.1216, 0.1333, 0.1647,  ..., 0.0471, 0.0353, 0.0314],\n",
      "          [0.0980, 0.1098, 0.1451,  ..., 0.0510, 0.0588, 0.0667],\n",
      "          [0.0824, 0.0980, 0.1333,  ..., 0.0353, 0.0549, 0.0667]],\n",
      "\n",
      "         [[0.1412, 0.1373, 0.1333,  ..., 0.3882, 0.3882, 0.3882],\n",
      "          [0.1333, 0.1294, 0.1255,  ..., 0.3922, 0.3922, 0.3922],\n",
      "          [0.1216, 0.1176, 0.1137,  ..., 0.3922, 0.3922, 0.3922],\n",
      "          ...,\n",
      "          [0.1608, 0.1725, 0.2039,  ..., 0.0863, 0.0745, 0.0706],\n",
      "          [0.1373, 0.1490, 0.1843,  ..., 0.0980, 0.1059, 0.1137],\n",
      "          [0.1216, 0.1373, 0.1725,  ..., 0.0941, 0.1137, 0.1255]],\n",
      "\n",
      "         [[0.1020, 0.0980, 0.0941,  ..., 0.3608, 0.3608, 0.3608],\n",
      "          [0.0941, 0.0902, 0.0863,  ..., 0.3608, 0.3608, 0.3608],\n",
      "          [0.0824, 0.0784, 0.0745,  ..., 0.3608, 0.3608, 0.3608],\n",
      "          ...,\n",
      "          [0.1098, 0.1216, 0.1412,  ..., 0.1255, 0.1137, 0.1098],\n",
      "          [0.0863, 0.0980, 0.1216,  ..., 0.1373, 0.1451, 0.1529],\n",
      "          [0.0706, 0.0863, 0.1098,  ..., 0.1294, 0.1490, 0.1608]]]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 1\n",
    "\n",
    "for x in iter(training_generator):\n",
    "    print(\"\\n\", type(x), len(x))\n",
    "    print(\"\\n\", type(x[0]), x[0].size())\n",
    "    print(x[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09545ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "def createDeepLabv3(outputchannels=1):\n",
    "    \"\"\"DeepLabv3 class with custom head\n",
    "    Args:\n",
    "        outputchannels (int, optional): The number of output channels\n",
    "        in your dataset masks. Defaults to 1.\n",
    "    Returns:\n",
    "        model: Returns the DeepLabv3 model with the ResNet101 backbone.\n",
    "    \"\"\"\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=True,\n",
    "                                                    progress=True)\n",
    "    model.classifier = DeepLabHead(2048, outputchannels)\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    return model\n",
    "\n",
    "model = createDeepLabv3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569a9b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Specify the loss function\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "# Specify the optimizer with a lower learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Specify the evaluation metrics\n",
    "metrics = {'f1_score': f1_score, 'auroc': roc_auc_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cbe6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = 1e10\n",
    "model.to(device)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_f1 = []\n",
    "test_f1 = []\n",
    "train_auroc = []\n",
    "test_auroc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25f7cfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "Train Loss: 0.2131\n",
      "Train Loss: 0.2821\n",
      "Train Loss: 0.2390\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28268/378409539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mtrain_auroc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\plantcv\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\plantcv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for phase in ['Train', 'Test']:\n",
    "        if phase == 'Train':\n",
    "            model.train()  # Set model to training mode\n",
    "            for sample in iter(training_generator):\n",
    "                inputs = sample[0].to(device)\n",
    "                inputs = inputs.to(torch.float32)\n",
    "                masks = sample[1].to(device)\n",
    "                masks = masks.to(torch.float32)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "#                 print(inputs.size(), masks.size())\n",
    "#                 print(inputs.dtype, masks.dtype)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs['out'], masks)\n",
    "                epoch_loss = loss.item()\n",
    "                \n",
    "                y_pred = outputs['out'].data.cpu().numpy().ravel()\n",
    "                y_true = masks.data.cpu().numpy().ravel()\n",
    "                train_f1.append(f1_score(y_true > 0, y_pred > 0.1))\n",
    "                train_auroc.append(roc_auc_score(y_true.astype('uint8'), y_pred))\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(epoch_loss)\n",
    "                print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "        \n",
    "        else:\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "        \n",
    "print(\"loss\", train_losses)\n",
    "print(\"f1\", train_f1)\n",
    "print(\"roc\", train_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9196cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
